# Copyright 2022-2023 XProbe Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import base64
import io
import logging
import os
from typing import Dict, List, Optional, Union

import gradio as gr
import PIL.Image
from gradio import Markdown

from ..client.restful.restful_client import RESTfulImageModelHandle

logger = logging.getLogger(__name__)


class ImageInterface:
    """
    å›¾åƒç”Ÿæˆç•Œé¢ç±»ï¼Œç”¨äºæ„å»ºå’Œç®¡ç†å›¾åƒç”Ÿæˆæ¨¡å‹çš„ç”¨æˆ·ç•Œé¢ã€‚

    è¯¥ç±»æä¾›äº†ä¸€ä¸ªé€šç”¨çš„æ¥å£ï¼Œç”¨äºåˆ›å»ºåŸºäºStable Diffusionæ¨¡å‹çš„å›¾åƒç”Ÿæˆç•Œé¢ã€‚
    å®ƒæ”¯æŒæ–‡æœ¬åˆ°å›¾åƒå’Œå›¾åƒåˆ°å›¾åƒçš„è½¬æ¢åŠŸèƒ½ã€‚

    å±æ€§:
        endpoint (str): APIç«¯ç‚¹URL
        model_uid (str): æ¨¡å‹çš„å”¯ä¸€æ ‡è¯†ç¬¦
        model_family (str): æ¨¡å‹æ‰€å±çš„ç³»åˆ—ï¼ˆå¦‚'stable_diffusion'ï¼‰
        model_name (str): æ¨¡å‹åç§°
        model_id (str): æ¨¡å‹ID
        model_revision (str): æ¨¡å‹ç‰ˆæœ¬
        model_ability (List[str]): æ¨¡å‹æ”¯æŒçš„èƒ½åŠ›åˆ—è¡¨
        controlnet (Union[None, List[Dict[str, Union[str, None]]]]): ControlNeté…ç½®
        access_token (Optional[str]): ç”¨äºAPIè®¤è¯çš„è®¿é—®ä»¤ç‰Œ
    """

    def __init__(
        self,
        endpoint: str,
        model_uid: str,
        model_family: str,
        model_name: str,
        model_id: str,
        model_revision: str,
        model_ability: List[str],
        controlnet: Union[None, List[Dict[str, Union[str, None]]]],
        access_token: Optional[str],
    ):
        """
        åˆå§‹åŒ–ImageInterfaceå®ä¾‹ã€‚

        å‚æ•°:
            endpoint (str): APIç«¯ç‚¹URL
            model_uid (str): æ¨¡å‹çš„å”¯ä¸€æ ‡è¯†ç¬¦
            model_family (str): æ¨¡å‹æ‰€å±çš„ç³»åˆ—
            model_name (str): æ¨¡å‹åç§°
            model_id (str): æ¨¡å‹ID
            model_revision (str): æ¨¡å‹ç‰ˆæœ¬
            model_ability (List[str]): æ¨¡å‹æ”¯æŒçš„èƒ½åŠ›åˆ—è¡¨
            controlnet (Union[None, List[Dict[str, Union[str, None]]]]): ControlNeté…ç½®
            access_token (Optional[str]): ç”¨äºAPIè®¤è¯çš„è®¿é—®ä»¤ç‰Œ
        """
        self.endpoint = endpoint
        self.model_uid = model_uid
        self.model_family = model_family
        self.model_name = model_name
        self.model_id = model_id
        self.model_revision = model_revision
        self.model_ability = model_ability
        self.controlnet = controlnet
        self.access_token = (
            access_token.replace("Bearer ", "") if access_token is not None else None
        )

    def build(self) -> gr.Blocks:
        """
        æ„å»ºä¸»ç•Œé¢ã€‚

        è¿”å›:
            gr.Blocks: é…ç½®å¥½çš„Gradioç•Œé¢å¯¹è±¡

        è¯¥æ–¹æ³•æ‰§è¡Œä»¥ä¸‹æ­¥éª¤:
        1. ç¡®ä¿æ¨¡å‹å±äº'stable_diffusion'ç³»åˆ—
        2. æ„å»ºä¸»ç•Œé¢
        3. é…ç½®ç•Œé¢é˜Ÿåˆ—
        4. æ‰‹åŠ¨è§¦å‘å¯åŠ¨äº‹ä»¶
        5. è®¾ç½®ç½‘é¡µå›¾æ ‡
        """
        assert "stable_diffusion" in self.model_family

        interface = self.build_main_interface()
        interface.queue()
        # Gradio initiates the queue during a startup event, but since the app has already been
        # started, that event will not run, so manually invoke the startup events.
        # See: https://github.com/gradio-app/gradio/issues/5228
        interface.startup_events()
        favicon_path = os.path.join(
            os.path.dirname(os.path.abspath(__file__)),
            os.path.pardir,
            "web",
            "ui",
            "public",
            "favicon.svg",
        )
        interface.favicon_path = favicon_path
        return interface

    def text2image_interface(self) -> "gr.Blocks":
        """
        æ„å»ºæ–‡æœ¬åˆ°å›¾åƒè½¬æ¢çš„ç•Œé¢ã€‚

        è¿”å›:
            gr.Blocks: æ–‡æœ¬åˆ°å›¾åƒè½¬æ¢çš„Gradioç•Œé¢å¯¹è±¡

        è¯¥æ–¹æ³•å®šä¹‰äº†ä¸€ä¸ªå†…éƒ¨å‡½æ•°text_generate_imageï¼Œç”¨äºå¤„ç†æ–‡æœ¬åˆ°å›¾åƒçš„è½¬æ¢è¯·æ±‚ã€‚
        ç„¶åï¼Œå®ƒåˆ›å»ºä¸€ä¸ªGradioç•Œé¢ï¼ŒåŒ…å«è¾“å…¥å­—æ®µï¼ˆå¦‚æç¤ºè¯ã€å›¾åƒæ•°é‡ã€å°ºå¯¸ç­‰ï¼‰å’Œè¾“å‡ºå›¾åº“ã€‚
        """

        def text_generate_image(
            prompt: str,
            n: int,
            size_width: int,
            size_height: int,
            num_inference_steps: int,
            negative_prompt: Optional[str] = None,
        ) -> PIL.Image.Image:
            """
            æ ¹æ®æ–‡æœ¬æç¤ºç”Ÿæˆå›¾åƒã€‚

            å‚æ•°:
                prompt (str): ç”¨äºç”Ÿæˆå›¾åƒçš„æ–‡æœ¬æç¤º
                n (int): è¦ç”Ÿæˆçš„å›¾åƒæ•°é‡
                size_width (int): ç”Ÿæˆå›¾åƒçš„å®½åº¦
                size_height (int): ç”Ÿæˆå›¾åƒçš„é«˜åº¦
                num_inference_steps (int): æ¨ç†æ­¥éª¤æ•°
                negative_prompt (Optional[str]): è´Ÿé¢æç¤ºè¯ï¼Œç”¨äºæŒ‡å®šä¸å¸Œæœ›å‡ºç°åœ¨å›¾åƒä¸­çš„å…ƒç´ 

            è¿”å›:
                List[PIL.Image.Image]: ç”Ÿæˆçš„å›¾åƒåˆ—è¡¨

            è¯¥å‡½æ•°æ‰§è¡Œä»¥ä¸‹æ­¥éª¤:
            1. åˆ›å»ºRESTfulå®¢æˆ·ç«¯å¹¶è·å–æ¨¡å‹
            2. è®¾ç½®å›¾åƒç”Ÿæˆå‚æ•°
            3. è°ƒç”¨æ¨¡å‹çš„text_to_imageæ–¹æ³•ç”Ÿæˆå›¾åƒ
            4. å°†è¿”å›çš„base64ç¼–ç å›¾åƒæ•°æ®è½¬æ¢ä¸ºPIL.Imageå¯¹è±¡
            5. è¿”å›ç”Ÿæˆçš„å›¾åƒåˆ—è¡¨
            """
            from ..client import RESTfulClient

            client = RESTfulClient(self.endpoint)
            client._set_token(self.access_token)
            model = client.get_model(self.model_uid)
            assert isinstance(model, RESTfulImageModelHandle)

            size = f"{int(size_width)}*{int(size_height)}"
            num_inference_steps = (
                None if num_inference_steps == -1 else num_inference_steps  # type: ignore
            )

            response = model.text_to_image(
                prompt=prompt,
                n=n,
                size=size,
                num_inference_steps=num_inference_steps,
                negative_prompt=negative_prompt,
                response_format="b64_json",
            )

            images = []
            for image_dict in response["data"]:
                assert image_dict["b64_json"] is not None
                image_data = base64.b64decode(image_dict["b64_json"])
                image = PIL.Image.open(io.BytesIO(image_data))
                images.append(image)

            return images

        with gr.Blocks() as text2image_vl_interface:
            # åˆ›å»ºæ–‡æœ¬åˆ°å›¾åƒç•Œé¢çš„Gradioç»„ä»¶
            # åŒ…æ‹¬æç¤ºè¯è¾“å…¥ã€è´Ÿé¢æç¤ºè¯è¾“å…¥ã€ç”ŸæˆæŒ‰é’®ã€å›¾åƒå‚æ•°è®¾ç½®å’Œè¾“å‡ºå›¾åº“
            with gr.Column():
                with gr.Row():
                    with gr.Column(scale=10):
                        prompt = gr.Textbox(
                            label="Prompt",
                            show_label=True,
                            placeholder="Enter prompt here...",
                        )
                        negative_prompt = gr.Textbox(
                            label="Negative prompt",
                            show_label=True,
                            placeholder="Enter negative prompt here...",
                        )
                    with gr.Column(scale=1):
                        generate_button = gr.Button("Generate")

                with gr.Row():
                    n = gr.Number(label="Number of Images", value=1)
                    size_width = gr.Number(label="Width", value=1024)
                    size_height = gr.Number(label="Height", value=1024)
                    num_inference_steps = gr.Number(
                        label="Inference Step Number", value=-1
                    )

                with gr.Column():
                    image_output = gr.Gallery()

            generate_button.click(
                text_generate_image,
                inputs=[
                    prompt,
                    n,
                    size_width,
                    size_height,
                    num_inference_steps,
                    negative_prompt,
                ],
                outputs=image_output,
            )

        return text2image_vl_interface

    def image2image_interface(self) -> "gr.Blocks":
        """
        æ„å»ºå›¾åƒåˆ°å›¾åƒè½¬æ¢çš„ç•Œé¢ã€‚

        è¿”å›:
            gr.Blocks: å›¾åƒåˆ°å›¾åƒè½¬æ¢çš„Gradioç•Œé¢å¯¹è±¡

        è¯¥æ–¹æ³•å®šä¹‰äº†ä¸€ä¸ªå†…éƒ¨å‡½æ•°image_generate_imageï¼Œç”¨äºå¤„ç†å›¾åƒåˆ°å›¾åƒçš„è½¬æ¢è¯·æ±‚ã€‚
        ç„¶åï¼Œå®ƒåˆ›å»ºä¸€ä¸ªGradioç•Œé¢ï¼ŒåŒ…å«è¾“å…¥å­—æ®µï¼ˆå¦‚æç¤ºè¯ã€å›¾åƒä¸Šä¼ ã€å‚æ•°è®¾ç½®ç­‰ï¼‰å’Œè¾“å‡ºå›¾åº“ã€‚
        """

        def image_generate_image(
            prompt: str,
            negative_prompt: str,
            image: PIL.Image.Image,
            n: int,
            size_width: int,
            size_height: int,
            num_inference_steps: int,
            padding_image_to_multiple: int,
        ) -> PIL.Image.Image:
            """
            æ ¹æ®è¾“å…¥å›¾åƒå’Œæ–‡æœ¬æç¤ºç”Ÿæˆæ–°å›¾åƒã€‚

            å‚æ•°:
                prompt (str): ç”¨äºç”Ÿæˆå›¾åƒçš„æ–‡æœ¬æç¤º
                negative_prompt (str): è´Ÿé¢æç¤ºè¯
                image (PIL.Image.Image): è¾“å…¥çš„æºå›¾åƒ
                n (int): è¦ç”Ÿæˆçš„å›¾åƒæ•°é‡
                size_width (int): ç”Ÿæˆå›¾åƒçš„å®½åº¦
                size_height (int): ç”Ÿæˆå›¾åƒçš„é«˜åº¦
                num_inference_steps (int): æ¨ç†æ­¥éª¤æ•°
                padding_image_to_multiple (int): å›¾åƒå¡«å……åˆ°çš„å€æ•°

            è¿”å›:
                List[PIL.Image.Image]: ç”Ÿæˆçš„å›¾åƒåˆ—è¡¨

            è¯¥å‡½æ•°æ‰§è¡Œä»¥ä¸‹æ­¥éª¤:
            1. åˆ›å»ºRESTfulå®¢æˆ·ç«¯å¹¶è·å–æ¨¡å‹
            2. è®¾ç½®å›¾åƒç”Ÿæˆå‚æ•°
            3. å°†è¾“å…¥å›¾åƒè½¬æ¢ä¸ºå­—èŠ‚æµ
            4. è°ƒç”¨æ¨¡å‹çš„image_to_imageæ–¹æ³•ç”Ÿæˆæ–°å›¾åƒ
            5. å°†è¿”å›çš„base64ç¼–ç å›¾åƒæ•°æ®è½¬æ¢ä¸ºPIL.Imageå¯¹è±¡
            6. è¿”å›ç”Ÿæˆçš„å›¾åƒåˆ—è¡¨
            """
            from ..client import RESTfulClient

            client = RESTfulClient(self.endpoint)
            client._set_token(self.access_token)
            model = client.get_model(self.model_uid)
            assert isinstance(model, RESTfulImageModelHandle)

            if size_width > 0 and size_height > 0:
                size = f"{int(size_width)}*{int(size_height)}"
            else:
                size = None
            num_inference_steps = (
                None if num_inference_steps == -1 else num_inference_steps  # type: ignore
            )
            padding_image_to_multiple = None if padding_image_to_multiple == -1 else padding_image_to_multiple  # type: ignore

            bio = io.BytesIO()
            image.save(bio, format="png")

            response = model.image_to_image(
                prompt=prompt,
                negative_prompt=negative_prompt,
                n=n,
                image=bio.getvalue(),
                size=size,
                response_format="b64_json",
                num_inference_steps=num_inference_steps,
                padding_image_to_multiple=padding_image_to_multiple,
            )

            images = []
            for image_dict in response["data"]:
                assert image_dict["b64_json"] is not None
                image_data = base64.b64decode(image_dict["b64_json"])
                image = PIL.Image.open(io.BytesIO(image_data))
                images.append(image)

            return images

        with gr.Blocks() as image2image_inteface:
            # åˆ›å»ºå›¾åƒåˆ°å›¾åƒç•Œé¢çš„Gradioç»„ä»¶
            # åŒ…æ‹¬æç¤ºè¯è¾“å…¥ã€è´Ÿé¢æç¤ºè¯è¾“å…¥ã€å›¾åƒä¸Šä¼ ã€å‚æ•°è®¾ç½®å’Œè¾“å‡ºå›¾åº“
            with gr.Column():
                with gr.Row():
                    with gr.Column(scale=10):
                        prompt = gr.Textbox(
                            label="Prompt",
                            show_label=True,
                            placeholder="Enter prompt here...",
                        )
                        negative_prompt = gr.Textbox(
                            label="Negative Prompt",
                            show_label=True,
                            placeholder="Enter negative prompt here...",
                        )
                    with gr.Column(scale=1):
                        generate_button = gr.Button("Generate")

                with gr.Row():
                    n = gr.Number(label="Number of image", value=1)
                    size_width = gr.Number(label="Width", value=-1)
                    size_height = gr.Number(label="Height", value=-1)

                with gr.Row():
                    num_inference_steps = gr.Number(
                        label="Inference Step Number", value=-1
                    )
                    padding_image_to_multiple = gr.Number(
                        label="Padding image to multiple", value=-1
                    )

                with gr.Row():
                    with gr.Column(scale=1):
                        uploaded_image = gr.Image(type="pil", label="Upload Image")
                    with gr.Column(scale=1):
                        output_gallery = gr.Gallery()

            generate_button.click(
                image_generate_image,
                inputs=[
                    prompt,
                    negative_prompt,
                    uploaded_image,
                    n,
                    size_width,
                    size_height,
                    num_inference_steps,
                    padding_image_to_multiple,
                ],
                outputs=output_gallery,
            )
        return image2image_inteface

    def build_main_interface(self) -> "gr.Blocks":
        """
        æ„å»ºä¸»ç•Œé¢ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ°å›¾åƒå’Œå›¾åƒåˆ°å›¾åƒçš„é€‰é¡¹å¡ã€‚

        è¿”å›:
            gr.Blocks: ä¸»ç•Œé¢çš„Gradioå¯¹è±¡

        è¯¥æ–¹æ³•åˆ›å»ºä¸€ä¸ªåŒ…å«å¤šä¸ªé€‰é¡¹å¡çš„ä¸»ç•Œé¢ï¼Œæ¯ä¸ªé€‰é¡¹å¡å¯¹åº”ä¸€ç§å›¾åƒç”ŸæˆåŠŸèƒ½ã€‚
        å®ƒè¿˜è®¾ç½®äº†ç•Œé¢çš„æ ‡é¢˜ã€CSSæ ·å¼å’Œå…¶ä»–å…ƒæ•°æ®ã€‚
        """
        with gr.Blocks(
            title=f"ğŸ¨ Xinference Stable Diffusion: {self.model_name} ğŸ¨",
            css="""
                    .center{
                        display: flex;
                        justify-content: center;
                        align-items: center;
                        padding: 0px;
                        color: #9ea4b0 !important;
                    }
                    """,
            analytics_enabled=False,
        ) as app:
            Markdown(
                f"""
                    <h1 class="center" style='text-align: center; margin-bottom: 1rem'>ğŸ¨ Xinference Stable Diffusion: {self.model_name} ğŸ¨</h1>
                    """
            )
            Markdown(
                f"""
                    <div class="center">
                    Model ID: {self.model_uid}
                    </div>
                    """
            )
            if "text2image" in self.model_ability:
                with gr.Tab("Text to Image"):
                    self.text2image_interface()
            if "image2image" in self.model_ability:
                with gr.Tab("Image to Image"):
                    self.image2image_interface()

        return app
